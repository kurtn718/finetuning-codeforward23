{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe12058-021e-41dc-91d6-712f2bc51325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/miniconda/envs/llm-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "import transformers\n",
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, LlamaForCausalLM, MistralForCausalLM, AutoTokenizer, LlamaTokenizerFast, GenerationConfig, TextGenerationPipeline, BatchEncoding\n",
    "from transformers.generation.utils import GreedySearchDecoderOnlyOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37774c71-d573-4936-af22-c7a1ae8b9d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['correct_answer', 'question', 'word', 'scrambled'],\n",
       "        num_rows: 6000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['correct_answer', 'question', 'word', 'scrambled'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['correct_answer', 'question', 'word', 'scrambled'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrambled_dataset_dict: DatasetDict = datasets.load_dataset(\"kurtn718/scrambled_words_multiple_choice\")\n",
    "scrambled_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad0e0f0c-f975-48aa-a24f-b786f8124756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'correct_answer': 'D', 'question': \"Find the right word for 'boderr'.\\nA: bdoerr\\nB: petite\\nC: oceania\\nD: border\", 'word': 'border', 'scrambled': 'boderr', 'prediction': ' d'}, {'correct_answer': 'C', 'question': \"What word does 'tlriaer' represent when unscrambled?\\nA: nevertheless\\nB: write\\nC: trailer\\nD: taelrlr\", 'word': 'trailer', 'scrambled': 'tlriaer', 'prediction': ' c'}, {'correct_answer': 'B', 'question': \"What word does 'ceruvs' represent when unscrambled?\\nA: failing\\nB: curves\\nC: assuming\\nD: cursed\", 'word': 'curves', 'scrambled': 'ceruvs', 'prediction': ' b'}, {'correct_answer': 'B', 'question': \"Rearrange the letters in 'sehlf' to form the correct word.\\nA: minds\\nB: shelf\\nC: slhef\\nD: aquarium\", 'word': 'shelf', 'scrambled': 'sehlf', 'prediction': ' B'}, {'correct_answer': 'A', 'question': \"Find the right word for 'begie'.\\nA: beige\\nB: impact\\nC: cruises\\nD: bgiee\", 'word': 'beige', 'scrambled': 'begie', 'prediction': ' a'}, {'correct_answer': 'B', 'question': \"Find the right word for 'kiawut'.\\nA: sunglasses\\nB: kuwait\\nC: threats\\nD: constructor\", 'word': 'kuwait', 'scrambled': 'kiawut', 'prediction': ' b'}, {'correct_answer': 'D', 'question': \"Decode the word 'rreagded'.\\nA: classification\\nB: pentium\\nC: enormous\\nD: regarded\", 'word': 'regarded', 'scrambled': 'rreagded', 'prediction': ' d'}, {'correct_answer': 'B', 'question': \"Rearrange the letters in 'orbesve' to form the correct word.\\nA: fairfield\\nB: observe\\nC: coupling\\nD: diverse\", 'word': 'observe', 'scrambled': 'orbesve', 'prediction': ' b'}, {'correct_answer': 'D', 'question': \"What word does 'bcaks' represent when unscrambled?\\nA: hood\\nB: tobacco\\nC: moon\\nD: backs\", 'word': 'backs', 'scrambled': 'bcaks', 'prediction': ' d'}, {'correct_answer': 'A', 'question': \"Decode the word 'ahoutr'.\\nA: author\\nB: giving\\nC: buffer\\nD: aruba\", 'word': 'author', 'scrambled': 'ahoutr', 'prediction': ' a'}, {'correct_answer': 'B', 'question': \"What word does 'veertan' represent when unscrambled?\\nA: adequately\\nB: veteran\\nC: reasonably\\nD: combining\", 'word': 'veteran', 'scrambled': 'veertan', 'prediction': ' b'}, {'correct_answer': 'D', 'question': \"Rearrange the letters in 'ppaadnogra' to form the correct word.\\nA: withdrawn\\nB: amino\\nC: cure\\nD: propaganda\", 'word': 'propaganda', 'scrambled': 'ppaadnogra', 'prediction': ' d'}, {'correct_answer': 'B', 'question': \"What word does 'liimts' represent when unscrambled?\\nA: admitted\\nB: limits\\nC: dates\\nD: taylor\", 'word': 'limits', 'scrambled': 'liimts', 'prediction': ' b'}, {'correct_answer': 'A', 'question': \"Can you unscramble 'stnkaig'?\\nA: skating\\nB: treating\\nC: trauma\\nD: lambda\", 'word': 'skating', 'scrambled': 'stnkaig', 'prediction': ' a'}, {'correct_answer': 'C', 'question': \"Find the right word for 'wreran'.\\nA: fairfield\\nB: asus\\nC: warren\\nD: drop\", 'word': 'warren', 'scrambled': 'wreran', 'prediction': ' c'}, {'correct_answer': 'B', 'question': \"What word does 'pierton' represent when unscrambled?\\nA: lisa\\nB: protein\\nC: fuels\\nD: torture\", 'word': 'protein', 'scrambled': 'pierton', 'prediction': ' b'}, {'correct_answer': 'C', 'question': \"Can you unscramble 'bolinggg'?\\nA: formulation\\nB: dude\\nC: blogging\\nD: blade\", 'word': 'blogging', 'scrambled': 'bolinggg', 'prediction': ' C'}]\n"
     ]
    }
   ],
   "source": [
    "test_dataset: Dataset = scrambled_dataset_dict[\"test\"]\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random_samples = random.sample(list(test_dataset), 17)\n",
    "\n",
    "test_dataset = [dict(sample) for sample in random_samples]\n",
    "\n",
    "with open('./exam_questions.json', 'r') as file:\n",
    "    test_dataset = json.load(file)\n",
    "\n",
    "\n",
    "# Convert samples to a list of dictionaries\n",
    "#data = [dict(sample) for sample in random_samples]\n",
    "#df_test = pd.DataFrame(data)\n",
    "\n",
    "#df_test: pd.DataFrame = test_dataset.to_pandas()\n",
    "#df_test = df_test.sample(n=200, random_state=200)\n",
    "\n",
    "#test_dataset: Dataset = scrambled_dataset_dict[\"test\"]\n",
    "print(test_dataset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7c42e4-887b-4559-a86d-f294b60bd7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name: str = \"kurtn718/scrambled_multiple_choice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd4070c7-5e71-4727-9d92-e457624d7cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n"
     ]
    }
   ],
   "source": [
    "base_model_tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name, trust_remote_code=True, padding_side=\"left\")\n",
    "print(base_model_tokenizer.eos_token)\n",
    "base_model_tokenizer.pad_token = base_model_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b374a327-de76-4d82-8859-d603649af4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 8/8 [00:00<00:00, 12.81it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:14<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer: LlamaTokenizerFast = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name, trust_remote_code=True, padding_side='left')\n",
    "bnb_config_fine_tuned_model: BitsAndBytesConfig = BitsAndBytesConfig(\n",
    "  load_in_8bit=True,\n",
    ")\n",
    "model: MistralForCausalLM = AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_name, torch_dtype=torch.float16, trust_remote_code=True, device_map=\"auto\", quantization_config=bnb_config_fine_tuned_model, low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd9c6ccd-7e68-4cc5-b459-8f2ddf192699",
   "metadata": {},
   "outputs": [],
   "source": [
    "scramble_sequences_generator: TextGenerationPipeline = transformers.pipeline(\n",
    "    task=\"text-generation\",\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4ed0c22-abc7-4d1b-b06f-6f1640c7525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing inference on 17 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n",
      "10 predicted.  10 words unscrambled correctly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " b\n",
      " C\n",
      "17 predicted.  17 words unscrambled correctly\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "num_correct = 0\n",
    "num_items = 0\n",
    "\n",
    "print(f\"Performing inference on {len(test_dataset)} items\") \n",
    "\n",
    "for row in test_dataset:\n",
    "    base_prompt = f\"\"\"\n",
    "    Answer the following question:\n",
    "\n",
    "    ### Question: {row['question']}\n",
    "\n",
    "    ### Answer:\n",
    "    \"\"\"\n",
    "   \n",
    "    scramble_sequences: list[dict] | list[list[dict]] = scramble_sequences_generator(\n",
    "        text_inputs=base_prompt,\n",
    "        do_sample=True,\n",
    "        top_k=50,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=128,\n",
    "        return_text=False,\n",
    "    )\n",
    "\n",
    "    scramble_sequence: dict = scramble_sequences[0]\n",
    "\n",
    "    scramble_sequences_generator: TextGenerationPipeline = transformers.pipeline(\n",
    "        task=\"text-generation\",\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    predicted_output = scramble_sequence[\"generated_text\"].removeprefix(base_prompt)\n",
    "    row['prediction'] = predicted_output\n",
    "    print(predicted_output)\n",
    "    if row['correct_answer'].lower() in predicted_output.lower():\n",
    "#        print(f\"Correct Answer: {row['correct_answer']}, Prediction: {predicted_output}\")\n",
    "#        print(\"Correct!\")\n",
    "#        print(f'\\n[GENERATED_TEXT] FINE_TUNED_MODEL_PREDICTION:\\n{scramble_sequence[\"generated_text\"]} ; Word: {row[\"scrambled\"]}')\n",
    "        num_correct = num_correct + 1\n",
    "    num_items = num_items + 1\n",
    "    if num_items % 10 == 0:\n",
    "        print(f\"{num_items} predicted.  {num_correct} words unscrambled correctly\")\n",
    "    \n",
    "print(f\"{num_items} predicted.  {num_correct} words unscrambled correctly\")\n",
    "\n",
    "with open('exam_questions.json', 'w') as json_file:\n",
    "    json.dump(test_dataset, json_file, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbd05a-d68a-44fb-996f-0f0fe77098d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1cf43-2c29-4518-94f8-5b939bde38c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-env",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
